{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatic File Formats Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Loka manage different clients with different needs depending the user use cases and business needs. This mean we need to be informed regards the different file formats we can see and the different storage technologies to allocated it, the diffetent posible processings it can suffer and the different analysis and ways to retrieve the informacion.\n",
    "\n",
    "This guide is designed to inform and give some bases to manage the diffent genetic formats.\n",
    "\n",
    "First at all it is important to determine the kind of life information we are treating. In life science we can see Omics information (Genomic, Proteomic and Metabolomic info), molecular and physico-chemical information, and clinical information. This guide only will cover Genomic information.\n",
    "\n",
    "In this notebook, we will explore some of the most common bioinformatics file formats: BCL, SRRA,  ,FASTA, BAM, BED, and VCF. We will see how these files are structured and how to read them using Python.\n",
    "\n",
    "It is important to firstly undestand the process to get the bioinformatic data.\n",
    "\n",
    "1. Sample Collection\n",
    "Obtaining Biological Samples: Biological samples such as blood, tissues, or cells from plants and animals are collected.\n",
    "Sample Preparation: The samples are prepared for analysis, which may include extracting DNA or RNA.\n",
    "2. Sequencing\n",
    "Sequencing Machines: The DNA or RNA samples are loaded into a sequencing machine. Illumina machines are very common.\n",
    "Data Generation: The machine reads the sequences of nucleotides (A, T, C, G) in the DNA or RNA and generates sequence data.\n",
    "3. Generation of Raw Data (BCL)\n",
    "BCL Files: Sequencing machines generate BCL files, which contain raw data of the base calls (the \"letters\" of the sequences) and their quality.\n",
    "4. Data Conversion (FASTQ)\n",
    "Conversion to FASTQ: The BCL files are converted to a more manageable format called FASTQ using specialized software. FASTQ files contain the DNA/RNA sequences and the quality of each base.\n",
    "Storage and Preprocessing: FASTQ files are stored and preprocessed to remove low-quality data or contaminants.\n",
    "5. Bioinformatics Analysis\n",
    "Sequence Analysis: FASTQ files are analyzed to identify genes, genetic variants, or to assemble complete genomes.\n",
    "Comparison with Databases: The sequences are compared with known sequence databases (e.g., using BLAST).\n",
    "6. Data Storage and Sharing (SRA)\n",
    "SRA Files: For archiving and sharing, sequence data can be stored in the Sequence Read Archive (SRA) format, which includes sequence reads and associated metadata.\n",
    "Data Submission: Researchers submit their sequencing data to repositories like NCBI, where it is stored in SRA format for public access and further research.\n",
    "In summary, the process starts with collecting and preparing biological samples, sequencing the DNA or RNA to generate raw data (BCL files), converting these to FASTQ files for analysis, and finally storing and sharing the data in SRA format. Each step involves specific tools and techniques to ensure the data is accurate, manageable, and useful for research.\n",
    "\n",
    "That said, we can proceed to explore the structure of each of the non binary file formats and how to operate on them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "To follow along with this notebook, you need to install the following libraries:\n",
    "```bash\n",
    "pip install biopython pysam pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glow library\n",
    "#### Description\n",
    "ddddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/spark/jars/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/aws-glue-libs/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/glue_user/aws-glue-libs/jars/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/glue_user/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/glue_user/.ivy2/cache\n",
      "The jars for the packages stored in: /home/glue_user/.ivy2/jars\n",
      "io.projectglow#glow-spark3_2.12 added as a dependency\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-47428e45-cad0-4420-829a-a1220304229f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.projectglow#glow-spark3_2.12;1.2.1 in central\n",
      "\tfound org.seqdoop#hadoop-bam;7.9.2 in central\n",
      "\tfound com.github.jsr203hadoop#jsr203hadoop;1.0.3 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.25 in central\n",
      "\tfound log4j#log4j;1.2.17 in central\n",
      "\tfound org.slf4j#slf4j-log4j12;1.7.25 in central\n",
      "\tfound org.jdbi#jdbi;2.63.1 in central\n",
      "\tfound com.github.broadinstitute#picard;2.21.9 in central\n",
      "\tfound com.intel.gkl#gkl;0.8.5 in central\n",
      "\tfound commons-io#commons-io;2.4 in central\n",
      "\tfound org.broadinstitute#gatk-native-bindings;0.1.0-rc-1 in central\n",
      "\tfound org.apache.logging.log4j#log4j-api;2.5 in central\n",
      "\tfound org.apache.logging.log4j#log4j-core;2.5 in central\n",
      "\tfound com.google.guava#guava;15.0 in central\n",
      "\tfound org.apache.commons#commons-math3;3.5 in central\n",
      "\tfound org.apache.commons#commons-collections4;4.3 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in central\n",
      "\tfound org.broadinstitute#barclay;2.0.0 in central\n",
      "\tfound net.sf.jopt-simple#jopt-simple;5.0.3 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.4 in central\n",
      "\tfound org.freemarker#freemarker;2.3.23 in central\n",
      "\tfound com.google.code.gson#gson;2.2.2 in central\n",
      "\tfound org.apache.hadoop#hadoop-client;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-common;3.3.1 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-protobuf_3_7;1.1.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;3.3.1 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound com.google.guava#guava;27.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound org.checkerframework#checker-qual;2.5.2 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.17 in central\n",
      "\tfound commons-cli#commons-cli;1.2 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound commons-io#commons-io;2.8.0 in central\n",
      "\tfound commons-net#commons-net;3.6 in central\n",
      "\tfound commons-collections#commons-collections;3.2.2 in central\n",
      "\tfound org.eclipse.jetty#jetty-servlet;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-security;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-webapp;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-xml;9.4.40.v20210413 in central\n",
      "\tfound com.sun.jersey#jersey-servlet;1.19 in central\n",
      "\tfound commons-beanutils#commons-beanutils;1.9.4 in central\n",
      "\tfound org.apache.commons#commons-configuration2;2.1.1 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.7 in central\n",
      "\tfound org.apache.commons#commons-text;1.4 in central\n",
      "\tfound org.apache.avro#avro;1.7.7 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.3 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.2 in central\n",
      "\tfound org.apache.commons#commons-compress;1.19 in central\n",
      "\tfound com.google.re2j#re2j;1.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound com.google.code.gson#gson;2.2.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-auth;3.3.1 in central\n",
      "\tfound com.nimbusds#nimbus-jose-jwt;9.8.1 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound net.minidev#json-smart;2.4.2 in central\n",
      "\tfound net.minidev#accessors-smart;2.4.2 in central\n",
      "\tfound org.ow2.asm#asm;5.0.4 in central\n",
      "\tfound org.apache.curator#curator-framework;4.2.0 in central\n",
      "\tfound org.apache.curator#curator-client;4.2.0 in central\n",
      "\tfound org.apache.kerby#kerb-simplekdc;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-client;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-config;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-core;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-pkix;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-asn1;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-util;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-common;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-crypto;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-util;1.0.1 in central\n",
      "\tfound org.apache.kerby#token-provider;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-admin;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-server;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-identity;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-xdr;1.0.1 in central\n",
      "\tfound org.apache.curator#curator-recipes;4.2.0 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.10.5.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.10.5 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.10.5 in central\n",
      "\tfound org.codehaus.woodstox#stax2-api;4.2.1 in central\n",
      "\tfound com.fasterxml.woodstox#woodstox-core;5.3.0 in central\n",
      "\tfound dnsjava#dnsjava;2.1.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-hdfs-client;3.3.1 in central\n",
      "\tfound com.squareup.okhttp#okhttp;2.7.5 in central\n",
      "\tfound com.squareup.okio#okio;1.6.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-api;3.3.1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.11 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-client;3.3.1 in central\n",
      "\tfound org.eclipse.jetty.websocket#websocket-client;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-client;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-http;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-io;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty.websocket#websocket-common;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty.websocket#websocket-api;9.4.40.v20210413 in central\n",
      "\tfound org.jline#jline;3.9.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-core;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-common;3.3.1 in central\n",
      "\tfound javax.servlet#javax.servlet-api;3.1.0 in central\n",
      "\tfound com.sun.jersey#jersey-core;1.19 in central\n",
      "\tfound javax.ws.rs#jsr311-api;1.1.1 in central\n",
      "\tfound com.sun.jersey#jersey-client;1.19 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.10.5 in central\n",
      "\tfound jakarta.xml.bind#jakarta.xml.bind-api;2.3.2 in central\n",
      "\tfound jakarta.activation#jakarta.activation-api;1.2.1 in central\n",
      "\tfound com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.10.5 in central\n",
      "\tfound com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.10.5 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-jobclient;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-common;3.3.1 in central\n",
      "\tfound javax.servlet.jsp#jsp-api;2.1 in central\n",
      "\tfound org.apache.zookeeper#zookeeper;3.5.6 in central\n",
      "\tfound org.apache.zookeeper#zookeeper-jute;3.5.6 in central\n",
      "\tfound org.apache.yetus#audience-annotations;0.5.0 in central\n",
      "\tfound com.google.inject#guice;4.0 in central\n",
      "\tfound javax.inject#javax.inject;1 in central\n",
      "\tfound aopalliance#aopalliance;1.0 in central\n",
      "\tfound com.sun.jersey#jersey-server;1.19 in central\n",
      "\tfound com.sun.jersey#jersey-json;1.19 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in central\n",
      "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in central\n",
      "\tfound com.sun.jersey.contribs#jersey-guice;1.19 in central\n",
      "\tfound io.netty#netty;3.9.9.Final in central\n",
      "\tfound io.netty#netty-all;4.1.68.Final in central\n",
      "\tfound io.netty#netty-handler;4.1.68.Final in central\n",
      "\tfound io.netty#netty-common;4.1.68.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.68.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.68.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.68.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.68.Final in central\n",
      "\tfound io.netty#netty-transport-native-epoll;4.1.68.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.68.Final in central\n",
      "\tfound com.github.samtools#htsjdk;2.21.2 in central\n",
      "\tfound org.apache.commons#commons-jexl;2.1.1 in central\n",
      "\tfound org.tukaani#xz;1.8 in central\n",
      "\tfound gov.nih.nlm.ncbi#ngs-java;2.9.0 in central\n",
      "\tfound org.yaml#snakeyaml;1.16 in central\n",
      "\tfound com.typesafe.scala-logging#scala-logging_2.12;3.7.2 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.2 in central\n",
      "\tfound io.delta#delta-core_2.12;2.1.0 in central\n",
      "\tfound io.delta#delta-storage;2.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      ":: resolution report :: resolve 1404ms :: artifacts dl 27ms\n",
      "\t:: modules in use:\n",
      "\taopalliance#aopalliance;1.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.10.5.1 from central in [default]\n",
      "\tcom.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.woodstox#woodstox-core;5.3.0 from central in [default]\n",
      "\tcom.github.broadinstitute#picard;2.21.9 from central in [default]\n",
      "\tcom.github.jsr203hadoop#jsr203hadoop;1.0.3 from central in [default]\n",
      "\tcom.github.samtools#htsjdk;2.21.2 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.2.4 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0 from central in [default]\n",
      "\tcom.google.guava#guava;27.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.inject#guice;4.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.1 from central in [default]\n",
      "\tcom.intel.gkl#gkl;0.8.5 from central in [default]\n",
      "\tcom.nimbusds#nimbus-jose-jwt;9.8.1 from central in [default]\n",
      "\tcom.squareup.okhttp#okhttp;2.7.5 from central in [default]\n",
      "\tcom.squareup.okio#okio;1.6.0 from central in [default]\n",
      "\tcom.sun.jersey#jersey-client;1.19 from central in [default]\n",
      "\tcom.sun.jersey#jersey-core;1.19 from central in [default]\n",
      "\tcom.sun.jersey#jersey-json;1.19 from central in [default]\n",
      "\tcom.sun.jersey#jersey-server;1.19 from central in [default]\n",
      "\tcom.sun.jersey#jersey-servlet;1.19 from central in [default]\n",
      "\tcom.sun.jersey.contribs#jersey-guice;1.19 from central in [default]\n",
      "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.3 from central in [default]\n",
      "\tcom.typesafe.scala-logging#scala-logging_2.12;3.7.2 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils;1.9.4 from central in [default]\n",
      "\tcommons-cli#commons-cli;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-collections#commons-collections;3.2.2 from central in [default]\n",
      "\tcommons-io#commons-io;2.8.0 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tcommons-net#commons-net;3.6 from central in [default]\n",
      "\tdnsjava#dnsjava;2.1.7 from central in [default]\n",
      "\tgov.nih.nlm.ncbi#ngs-java;2.9.0 from central in [default]\n",
      "\tio.delta#delta-core_2.12;2.1.0 from central in [default]\n",
      "\tio.delta#delta-storage;2.1.0 from central in [default]\n",
      "\tio.netty#netty;3.9.9.Final from central in [default]\n",
      "\tio.netty#netty-all;4.1.68.Final from central in [default]\n",
      "\tio.netty#netty-buffer;4.1.68.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.68.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.68.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.68.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.68.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.68.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-epoll;4.1.68.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.68.Final from central in [default]\n",
      "\tio.projectglow#glow-spark3_2.12;1.2.1 from central in [default]\n",
      "\tjakarta.activation#jakarta.activation-api;1.2.1 from central in [default]\n",
      "\tjakarta.xml.bind#jakarta.xml.bind-api;2.3.2 from central in [default]\n",
      "\tjavax.inject#javax.inject;1 from central in [default]\n",
      "\tjavax.servlet#javax.servlet-api;3.1.0 from central in [default]\n",
      "\tjavax.servlet.jsp#jsp-api;2.1 from central in [default]\n",
      "\tjavax.ws.rs#jsr311-api;1.1.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.11 from central in [default]\n",
      "\tlog4j#log4j;1.2.17 from central in [default]\n",
      "\tnet.minidev#accessors-smart;2.4.2 from central in [default]\n",
      "\tnet.minidev#json-smart;2.4.2 from central in [default]\n",
      "\tnet.sf.jopt-simple#jopt-simple;5.0.3 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.apache.avro#avro;1.7.7 from central in [default]\n",
      "\torg.apache.commons#commons-collections4;4.3 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.19 from central in [default]\n",
      "\torg.apache.commons#commons-configuration2;2.1.1 from central in [default]\n",
      "\torg.apache.commons#commons-jexl;2.1.1 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.7 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.5 from central in [default]\n",
      "\torg.apache.commons#commons-text;1.4 from central in [default]\n",
      "\torg.apache.curator#curator-client;4.2.0 from central in [default]\n",
      "\torg.apache.curator#curator-framework;4.2.0 from central in [default]\n",
      "\torg.apache.curator#curator-recipes;4.2.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-auth;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-common;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-hdfs-client;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-common;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-core;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-jobclient;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-client;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-common;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-protobuf_3_7;1.1.1 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.kerby#kerb-admin;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-client;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-common;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-core;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-crypto;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-identity;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-server;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-simplekdc;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-util;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-asn1;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-config;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-pkix;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-util;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-xdr;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#token-provider;1.0.1 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-api;2.5 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-core;2.5 from central in [default]\n",
      "\torg.apache.yetus#audience-annotations;0.5.0 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper;3.5.6 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper-jute;3.5.6 from central in [default]\n",
      "\torg.broadinstitute#barclay;2.0.0 from central in [default]\n",
      "\torg.broadinstitute#gatk-native-bindings;0.1.0-rc-1 from central in [default]\n",
      "\torg.checkerframework#checker-qual;2.5.2 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-xc;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.17 from central in [default]\n",
      "\torg.codehaus.woodstox#stax2-api;4.2.1 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-client;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-http;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-io;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-security;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-servlet;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-webapp;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-xml;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty.websocket#websocket-api;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty.websocket#websocket-client;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty.websocket#websocket-common;9.4.40.v20210413 from central in [default]\n",
      "\torg.freemarker#freemarker;2.3.23 from central in [default]\n",
      "\torg.jdbi#jdbi;2.63.1 from central in [default]\n",
      "\torg.jline#jline;3.9.0 from central in [default]\n",
      "\torg.ow2.asm#asm;5.0.4 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.2 from central in [default]\n",
      "\torg.seqdoop#hadoop-bam;7.9.2 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 from central in [default]\n",
      "\torg.slf4j#slf4j-log4j12;1.7.25 from central in [default]\n",
      "\torg.tukaani#xz;1.8 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.2 from central in [default]\n",
      "\torg.yaml#snakeyaml;1.16 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.apache.hadoop#hadoop-client;2.2.0 by [org.apache.hadoop#hadoop-client;3.3.1] in [default]\n",
      "\tcom.github.samtools#htsjdk;2.13.2 by [com.github.samtools#htsjdk;2.21.2] in [default]\n",
      "\tcommons-io#commons-io;2.4 by [commons-io#commons-io;2.8.0] in [default]\n",
      "\tcom.google.guava#guava;15.0 by [com.google.guava#guava;27.0-jre] in [default]\n",
      "\tcom.github.samtools#htsjdk;2.21.0 by [com.github.samtools#htsjdk;2.21.2] in [default]\n",
      "\torg.apache.commons#commons-lang3;3.4 by [org.apache.commons#commons-lang3;3.7] in [default]\n",
      "\torg.apache.logging.log4j#log4j-api;2.3 by [org.apache.logging.log4j#log4j-api;2.5] in [default]\n",
      "\torg.apache.logging.log4j#log4j-core;2.3 by [org.apache.logging.log4j#log4j-core;2.5] in [default]\n",
      "\tcom.google.code.gson#gson;2.2.2 by [com.google.code.gson#gson;2.2.4] in [default]\n",
      "\torg.apache.commons#commons-math3;3.1.1 by [org.apache.commons#commons-math3;3.5] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 by [org.slf4j#slf4j-api;1.7.25] in [default]\n",
      "\tcommons-logging#commons-logging;1.1.1 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.7.3 by [org.xerial.snappy#snappy-java;1.1.8.2] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |  161  |   0   |   0   |   13  ||  148  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-47428e45-cad0-4420-829a-a1220304229f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 148 already retrieved (0kB/27ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession whit configuration required\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Glow with PySpark\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.projectglow:glow-spark3_2.12:1.2.1,io.delta:delta-core_2.12:2.1.0\") \\\n",
    "    .config(\"spark.hadoop.io.compression.codecs\", \"io.projectglow.sql.util.BGZFCodec\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCF Format\n",
    "\n",
    "#### Description\n",
    "The VCF (Variant Call Format) is used to store genomic variants such as SNPs, indels, and other structural variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see the structure of the most basic non binary formartmats we can start exploring some good architecture practices to store and process it.\n",
    "\n",
    "Depending of the kind of project we are working, we will need to store and process different genomic formats. Lets supose we have a client which need to store every kind of bioinformatic formats, raw reads (BCL) and processed files (FASTA, FASTQ, GFF3, SAM, VCF).\n",
    "\n",
    "For raw read formats, these can be stored in a data lake using S3, where they can be indexed and partitioned for easier access using patters susch as tenant/year/month/day/file/ which will then be used to process them and run the secondary analyses that will generate the other formats that will allow us to extract information of interest to produce biological insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BCL to (FASTA or FASTAQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('vcf').load(\"../data/example1000g_chr22_MAF05.vcf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/14 15:07:19 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Row(contigName='22', start=16051248), Row(contigName='17', start=504217))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"contigName\", \"start\").head(), Row(contigName='17', start=504217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"../data/delta/variants_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107658"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format('delta').load(\"../data/delta/variants_delta\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFF3 Format\n",
    "\n",
    "#### Description\n",
    "GFF3 (General Feature Format Version 3) is a standard file format used to describe genes and other features of DNA, RNA, and protein sequences. GFF3 files are widely used in genomics for storing annotation data, which includes information about genomic features such as exons, introns, regulatory regions, and more. The format is highly structured and allows for hierarchical relationships between features, making it suitable for complex annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure of GFF3\n",
    "A typical GFF3 file consists of nine columns, which include:\n",
    "\n",
    "- Seqid: The name of the sequence (e.g., chromosome name).\n",
    "- Source: The source of the annotation (e.g., the name of the program that generated this feature).\n",
    "- Type: The type of feature (e.g., gene, exon, CDS).\n",
    "- Start: The start position of the feature.\n",
    "- End: The end position of the feature.\n",
    "- Score: A floating-point score associated with the feature.\n",
    "- Strand: The strand of the feature (+ or -).\n",
    "- Phase: The phase of the feature (relevant for CDS features).\n",
    "- Attributes: A list of tag-value pairs providing additional information.\n",
    "\n",
    "#### Uses of GFF3\n",
    "GFF3 files are used for:\n",
    "\n",
    "**Genomic Annotation:** Storing the locations and characteristics of genes and other features on genomes.\n",
    "**Comparative Genomics:** Comparing gene annotations across different species.\n",
    "**Bioinformatics Pipelines:** Serving as input for various bioinformatics tools that analyze genomic data.\n",
    "\n",
    "#### Manipulating GFF3 with Glow and Delta Lake\n",
    "Glow is an open-source toolkit for large-scale genomic data analysis on Apache Spark. It extends Spark's capabilities with genomic data types and functions, allowing seamless integration with standard formats like GFF3.\n",
    "\n",
    "Delta Lake is an open-source storage layer that brings reliability to data lakes. It provides ACID transactions, scalable metadata handling, and unified streaming and batch data processing.\n",
    "\n",
    "#### Reading GFF3 with Glow\n",
    "\n",
    "To read a GFF3 file using Glow and Apache Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff3_df = spark.read.format(\"gff\").load(\"../data/example.gff3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----+-----+----+-----+------+-----+-----+-----------+-------+\n",
      "|seqId|source|type|start| end|score|strand|phase|   ID|       Name| Parent|\n",
      "+-----+------+----+-----+----+-----+------+-----+-----+-----------+-------+\n",
      "| seq1|  null|gene|  999|2000| null|     +| null|gene1|      Gene1|   null|\n",
      "| seq1|  null|mRNA| 1049|1800| null|     +| null|mRNA1|Transcript1|[gene1]|\n",
      "| seq1|  null|exon| 1049|1200| null|     +| null|exon1|      Exon1|[mRNA1]|\n",
      "| seq1|  null|exon| 1249|1500| null|     +| null|exon2|      Exon2|[mRNA1]|\n",
      "| seq1|  null|exon| 1549|1800| null|     +| null|exon3|      Exon3|[mRNA1]|\n",
      "| seq1|  null| CDS| 1059|1190| null|     +|    0| cds1|       null|[mRNA1]|\n",
      "| seq1|  null| CDS| 1259|1490| null|     +|    0| cds2|       null|[mRNA1]|\n",
      "| seq1|  null| CDS| 1559|1790| null|     +|    0| cds3|       null|[mRNA1]|\n",
      "+-----+------+----+-----+----+-----+------+-----+-----+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gff3_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[seqId: string, source: string, type: string, start: bigint, end: bigint, score: double, strand: string, phase: int, ID: string, Name: string, Parent: array<string>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Number of records: {gff3_df.count()}\")\n",
    "display(gff3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_original_gff_df = gff3_df.select(['start', 'end', 'type', 'seqId', 'source', 'strand', 'phase', 'ID', 'Name', 'Parent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----+-----+------+------+-----+-----+-----------+-------+\n",
      "|start| end|type|seqId|source|strand|phase|   ID|       Name| Parent|\n",
      "+-----+----+----+-----+------+------+-----+-----+-----------+-------+\n",
      "|  999|2000|gene| seq1|  null|     +| null|gene1|      Gene1|   null|\n",
      "| 1049|1800|mRNA| seq1|  null|     +| null|mRNA1|Transcript1|[gene1]|\n",
      "| 1049|1200|exon| seq1|  null|     +| null|exon1|      Exon1|[mRNA1]|\n",
      "| 1249|1500|exon| seq1|  null|     +| null|exon2|      Exon2|[mRNA1]|\n",
      "| 1549|1800|exon| seq1|  null|     +| null|exon3|      Exon3|[mRNA1]|\n",
      "| 1059|1190| CDS| seq1|  null|     +|    0| cds1|       null|[mRNA1]|\n",
      "| 1259|1490| CDS| seq1|  null|     +|    0| cds2|       null|[mRNA1]|\n",
      "| 1559|1790| CDS| seq1|  null|     +|    0| cds3|       null|[mRNA1]|\n",
      "+-----+----+----+-----+------+------+-----+-----+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etl_original_gff_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotate chromosome (contigName) to gff3 dataframe\n",
    "Selecting regions and joining back to original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|seqId|   ID|\n",
      "+-----+-----+\n",
      "| seq1|exon1|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regions_df = gff3_df.where((f.col(\"type\") == \"exon\") & (f.col(\"Name\") == \"Exon1\")). \\\n",
    "                             select(\"seqId\", \"ID\")\n",
    "regions_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff3_df.write.mode(\"overwrite\").format(\"delta\").save(\"../data/delta/gff3_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format('delta').load(\"../data/delta/gff3_delta\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
